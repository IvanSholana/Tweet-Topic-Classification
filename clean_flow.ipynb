{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load All Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize, sent_tokenize, FreqDist\n",
    "from nltk.classify import SklearnClassifier\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "nltk.download\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import re\n",
    "\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "import preprocessor as p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./dataset/raw dataset/dataset_penyisihan_bdc_2024.csv\",sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data Assesment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    5000 non-null   object\n",
      " 1   label   5000 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 78.2+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "text     5000\n",
       "label    5000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.info()\n",
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Demografi</th>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ekonomi</th>\n",
       "      <td>367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Geografi</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ideologi</th>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pertahanan dan Keamanan</th>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Politik</th>\n",
       "      <td>2972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sosial Budaya</th>\n",
       "      <td>587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sumber Daya Alam</th>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         text\n",
       "label                        \n",
       "Demografi                  62\n",
       "Ekonomi                   367\n",
       "Geografi                   20\n",
       "Ideologi                  400\n",
       "Pertahanan dan Keamanan   400\n",
       "Politik                  2972\n",
       "Sosial Budaya             587\n",
       "Sumber Daya Alam          192"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('label').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Clean Data (Drop Duplicate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean = data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Split Camel Case and Cleaning from Twitter Format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tweet(data):\n",
    "    text = data['preprocessed']\n",
    "    text = p.clean(text)\n",
    "    return text\n",
    "\n",
    "def split_camel_case(text):\n",
    "    return [re.sub(r'([a-z])([A-Z])', r'\\1 \\2', i) for i in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_23600\\2147847194.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_clean['preprocessed_hastag'] = data['hastag'].apply(split_camel_case)\n"
     ]
    }
   ],
   "source": [
    "data['hastag'] = data['text'].apply(lambda x: re.findall(f\"#(\\w+)\",x))\n",
    "data_clean['preprocessed_hastag'] = data['hastag'].apply(split_camel_case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Lower The Text and Split The Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_23600\\1267249655.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_clean['preprocessed_hastag'] = data_clean['preprocessed_hastag'].apply(lambda x: [i.lower() for i in x])\n",
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_23600\\1267249655.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_clean['preprocessed_hastag'] = data_clean['preprocessed_hastag'].apply(lambda x: ' '.join(x).split())\n"
     ]
    }
   ],
   "source": [
    "data_clean['preprocessed_hastag'] = data_clean['preprocessed_hastag'].apply(lambda x: [i.lower() for i in x])\n",
    "data_clean['preprocessed_hastag'] = data_clean['preprocessed_hastag'].apply(lambda x: ' '.join(x).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>preprocessed_hastag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kunjungan Prabowo ini untuk meresmikan dan men...</td>\n",
       "      <td>Sumber Daya Alam</td>\n",
       "      <td>[indonesia, sentris, indonesia, hijau, 02melan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT Anies dapat tepuk tangan meriah saat jadi R...</td>\n",
       "      <td>Politik</td>\n",
       "      <td>[amin, miskinkan, koruptor]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@CIqXqwGAT04tMtx4OCATxjoVq7vv/Y8HeYaIOgMFg8Y= ...</td>\n",
       "      <td>Demografi</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @L3R8XFBw3WGbxRPSj0/0hHZTbqVGX7qtfwRg9zmhK7...</td>\n",
       "      <td>Politik</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anies Baswedan Harap ASN termasuk TNI dan Polr...</td>\n",
       "      <td>Politik</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text             label  \\\n",
       "0  Kunjungan Prabowo ini untuk meresmikan dan men...  Sumber Daya Alam   \n",
       "1  RT Anies dapat tepuk tangan meriah saat jadi R...           Politik   \n",
       "2  @CIqXqwGAT04tMtx4OCATxjoVq7vv/Y8HeYaIOgMFg8Y= ...         Demografi   \n",
       "3  RT @L3R8XFBw3WGbxRPSj0/0hHZTbqVGX7qtfwRg9zmhK7...           Politik   \n",
       "4  Anies Baswedan Harap ASN termasuk TNI dan Polr...           Politik   \n",
       "\n",
       "                                 preprocessed_hastag  \n",
       "0  [indonesia, sentris, indonesia, hijau, 02melan...  \n",
       "1                        [amin, miskinkan, koruptor]  \n",
       "2                                                 []  \n",
       "3                                                 []  \n",
       "4                                                 []  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Clean @ or (USERNAME) and # or (HASTAG) in Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_23600\\2418940909.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_clean['preprocessed'] = data_clean['text'].apply(lambda x : clean_username(x))\n"
     ]
    }
   ],
   "source": [
    "def clean_username(text):\n",
    "    return re.sub(r'[@#]\\S+', '', text)\n",
    "\n",
    "data_clean['preprocessed'] = data_clean['text'].apply(lambda x : clean_username(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Combine Hastag and Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_23600\\113627744.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_clean['preprocessed'] = data_clean['preprocessed'].apply(lambda x : x.split())\n",
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_23600\\113627744.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_clean['preprocessed'] = data_clean['preprocessed'] + data_clean['preprocessed_hastag']\n",
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_23600\\113627744.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_clean['preprocessed'] = data_clean['preprocessed'].apply(lambda x : ' '.join(x))\n"
     ]
    }
   ],
   "source": [
    "data_clean['preprocessed'] = data_clean['preprocessed'].apply(lambda x : x.split())\n",
    "data_clean['preprocessed'] = data_clean['preprocessed'] + data_clean['preprocessed_hastag']\n",
    "data_clean['preprocessed'] = data_clean['preprocessed'].apply(lambda x : ' '.join(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Lower, Delete Punctuation, and Delete Double Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "data_clean['lower'] = data_clean['preprocessed'].str.lower().str.replace(\"[^\\w\\s]\",\"\").str.replace(\"\\s\\s+\",\"\")\n",
    "\n",
    "for index,row in data_clean.iterrows():\n",
    "    row['lower'] = row['lower'].translate(str.maketrans('','',string.punctuation))\n",
    "    data_clean['lower'][index] = row['lower']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Clean HTTPS and Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_23600\\4030215978.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_clean['clean'] = data_clean['lower'].apply(lambda x: re.sub(r'\\d+', '', x))\n",
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_23600\\4030215978.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_clean['clean'] = data_clean['lower'].apply(lambda x: re.sub(r'\\b\\w*https\\w*\\b', '', x))\n"
     ]
    }
   ],
   "source": [
    "data_clean['clean'] = data_clean['lower'].apply(lambda x: re.sub(r'\\d+', '', x))\n",
    "data_clean['clean'] = data_clean['lower'].apply(lambda x: re.sub(r'\\b\\w*https\\w*\\b', '', x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. CHANGE NON FORMAL TO FORMAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_23600\\3932693264.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_clean[\"formal\"] = formal_tokens\n"
     ]
    }
   ],
   "source": [
    "slang_list = pd.read_csv(\"./dataset/corpus dataset/colloquial-indonesian-lexicon.csv\")\n",
    "slang = slang_list['slang'].values.tolist()\n",
    "formal = slang_list['formal'].values.tolist()\n",
    "slangToformal = dict(zip(slang,formal))\n",
    "\n",
    "formal_tokens = []\n",
    "for index,row in data_clean.iterrows():\n",
    "    temp = []\n",
    "    for word in row['clean'].split():\n",
    "        temp.append(slangToformal.get(word,word))\n",
    "    res = \" \".join(temp)\n",
    "    formal_tokens.append(res)\n",
    "data_clean[\"formal\"] = formal_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Cleaning Word that Start With Re (Retweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_23600\\2252865480.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_clean['formal'] = data_clean['formal'].str.replace(r're\\s+\\S+', '',regex=True)\n"
     ]
    }
   ],
   "source": [
    "data_clean['formal'] = data_clean['formal'].str.replace(r're\\s+\\S+', '',regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Lematisasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_23600\\3671842305.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_clean['lemmatized']=lemmatized\n"
     ]
    }
   ],
   "source": [
    "from nlp_id.lemmatizer import Lemmatizer\n",
    "\n",
    "lemmatizer = Lemmatizer()\n",
    "lemmatized=[]\n",
    "for index, row in data_clean.iterrows():\n",
    "    lemmatized.append(lemmatizer.lemmatize(row['formal']))\n",
    "\n",
    "data_clean['lemmatized']=lemmatized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. Stopword Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_23600\\2645367154.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_clean['stopword_removed']=stopword_removed\n"
     ]
    }
   ],
   "source": [
    "from nlp_id.stopword import StopWord\n",
    "\n",
    "stopword = StopWord()\n",
    "stopword_removed=[]\n",
    "\n",
    "for index, row in data_clean.iterrows():\n",
    "    stopword_removed.append(stopword.remove_stopword(row['lemmatized']))\n",
    "\n",
    "data_clean['stopword_removed']=stopword_removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. Tokenisasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_23600\\2005421490.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_clean['tokens']=tokens_c\n"
     ]
    }
   ],
   "source": [
    "from nlp_id.tokenizer import Tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "tokens_c=[]\n",
    "\n",
    "for index, row in data_clean.iterrows():\n",
    "    tokens = tokenizer.tokenize(row['stopword_removed'])\n",
    "    tokens_c.append(tokens)\n",
    "\n",
    "data_clean['tokens']=tokens_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15. Second Stopword Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_23600\\3561544505.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_clean['stopword_removed2'] = data_clean['tokens'].apply(lambda x: [item for item in x if item not in stopwords_all])\n"
     ]
    }
   ],
   "source": [
    "#augment the stopwords with nonstandard twitter words\n",
    "stopwords_set = set(stopwords.words(\"indonesian\"))\n",
    "stopwords_aug = {\"ya\",\"yak\",\"iya\",\"yg\",\"ga\",\"gak\",\"gk\",\"udh\",\"sdh\",\"udah\",\"dah\",\"nih\",\"ini\",\"deh\",\"sih\",\"dong\",\"donk\",\n",
    "                 \"sm\",\"knp\",\"utk\",\"yaa\",\"tdk\",\"gini\",\"gitu\",\"bgt\",\"gt\",\"nya\",\"kalo\",\"cb\",\"jg\",\"jgn\",\"gw\",\"ge\",\n",
    "                 \"sy\",\"min\",\"mas\",\"mba\",\"mbak\",\"pak\",\"kak\",\"trus\",\"trs\",\"bs\",\"bisa\",\"aja\",\"saja\",\"no\",\n",
    "                 \"w\",\"g\",\"gua\",\"gue\",\"emang\",\"emg\",\"wkwk\",\"dr\",\"kau\",\"dg\",\"gimana\",\"apapun\",\"apa\",\n",
    "                 \"klo\",\"yah\",\"banget\",\"pake\",\"terus\",\"krn\",\"jadi\",\"jd\",\"mu\",\"ku\",\"si\",\"hehe\",\n",
    "                 \"tp\",\"pa\",\"lu\",\"lo\",\"lw\",\"tw\",\"tau\",\"karna\",\"kayak\",\"ky\",\"lg\",\"untuk\",\"tuk\",\"dg\",\"dgn\"}\n",
    "stopwords_all = stopwords_set.union(stopwords_aug)\n",
    "\n",
    "data_clean['stopword_removed2'] = data_clean['tokens'].apply(lambda x: [item for item in x if item not in stopwords_all])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16. Remove Digit in List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_23600\\1636423664.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_clean['stopword_removed2'] = data_clean['stopword_removed2'].apply(lambda x : [item for item in x if not item.isdigit()])\n"
     ]
    }
   ],
   "source": [
    "data_clean['stopword_removed2'] = data_clean['stopword_removed2'].apply(lambda x : [item for item in x if not item.isdigit()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17. Translate to Indonesia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "def translate_to_indonesian(text):\n",
    "    translated_text = GoogleTranslator(source='en', target='id').translate(text)\n",
    "    return translated_text\n",
    "\n",
    "indices_to_translate = [40, 415, 1646, 2973, 3767, 3721, 4736, 392,39,772,1121,1269,1787,306,2271,2344,17]\n",
    "\n",
    "def conditional_translation(row, index):\n",
    "    if index in indices_to_translate:\n",
    "        return translate_to_indonesian(' '.join(row))\n",
    "    else:\n",
    "        return ' '.join(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_23600\\3102551940.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_clean['stopword_removed2'] = data_clean.apply(\n"
     ]
    }
   ],
   "source": [
    "data_clean['stopword_removed2'] = data_clean.apply(\n",
    "    lambda row: conditional_translation(row['stopword_removed2'], row.name),\n",
    "    axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18. Filter in KBBI Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "kbbi_corpus = pd.read_csv(\"./dataset/corpus dataset/kbbi.csv\")\n",
    "kbbi_corpus.drop_duplicates(inplace=True)\n",
    "list_kbbi = kbbi_corpus['kata'].to_list()\n",
    "\n",
    "def hapus_kata_non_sastrawi(kata_list):\n",
    "    kata_list = kata_list.split()\n",
    "    return [kata for kata in kata_list if kata in list_kbbi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_23600\\2736237675.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_clean['KBBI'] = data_clean['stopword_removed2'].apply(hapus_kata_non_sastrawi)\n"
     ]
    }
   ],
   "source": [
    "# Terapkan fungsi ke kolom stopword_removed2\n",
    "data_clean['KBBI'] = data_clean['stopword_removed2'].apply(hapus_kata_non_sastrawi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19. Remove Word that Just Consist of 2 Letter and Replace Milu to Pemilu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_23600\\1707700021.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_clean['cleaned_KBBI'] = data_clean['KBBI'].apply(clear_list)\n"
     ]
    }
   ],
   "source": [
    "def clear_list(clear2List):\n",
    "    # Menghapus elemen dengan panjang kurang dari atau sama dengan 2 karakter\n",
    "    list_karakter = [item for item in clear2List if len(item) > 2]\n",
    "\n",
    "    # Mengganti semua kemunculan \"milu\" menjadi \"pemilu\" di dalam list\n",
    "    for i in range(len(list_karakter)):\n",
    "        list_karakter[i] = list_karakter[i].replace(\"milu\", \"pemilu\")\n",
    "    \n",
    "    return list_karakter\n",
    "\n",
    "data_clean['cleaned_KBBI'] = data_clean['KBBI'].apply(clear_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20. Optional Make it To Unique Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_23600\\4079798604.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_clean['unique_teks'] = data_clean['cleaned_KBBI'].apply(lambda x : ' '.join(set(x)))\n"
     ]
    }
   ],
   "source": [
    "data_clean['unique_teks'] = data_clean['cleaned_KBBI'].apply(lambda x : ' '.join(set(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21. Drop Nan Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_23600\\2410125117.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_clean.dropna(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "data_clean.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>preprocessed_hastag</th>\n",
       "      <th>preprocessed</th>\n",
       "      <th>lower</th>\n",
       "      <th>clean</th>\n",
       "      <th>formal</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>stopword_removed</th>\n",
       "      <th>tokens</th>\n",
       "      <th>stopword_removed2</th>\n",
       "      <th>KBBI</th>\n",
       "      <th>cleaned_KBBI</th>\n",
       "      <th>unique_teks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kunjungan Prabowo ini untuk meresmikan dan men...</td>\n",
       "      <td>Sumber Daya Alam</td>\n",
       "      <td>[indonesia, sentris, indonesia, hijau, 02melan...</td>\n",
       "      <td>Kunjungan Prabowo ini untuk meresmikan dan men...</td>\n",
       "      <td>kunjungan prabowo ini untuk meresmikan dan men...</td>\n",
       "      <td>kunjungan prabowo ini untuk meresmikan dan men...</td>\n",
       "      <td>kunjungan prabowo ini untuk meresmikan dan men...</td>\n",
       "      <td>kunjung prabowo ini untuk resmi dan serah proy...</td>\n",
       "      <td>kunjung prabowo resmi serah proyek bantu air b...</td>\n",
       "      <td>[kunjung, prabowo, resmi, serah, proyek, bantu...</td>\n",
       "      <td>kunjung prabowo resmi serah proyek bantu air b...</td>\n",
       "      <td>[kunjung, prabowo, resmi, serah, proyek, bantu...</td>\n",
       "      <td>[kunjung, prabowo, resmi, serah, proyek, bantu...</td>\n",
       "      <td>titik anak kunjung hijau bantu prabowo emas mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT Anies dapat tepuk tangan meriah saat jadi R...</td>\n",
       "      <td>Politik</td>\n",
       "      <td>[amin, miskinkan, koruptor]</td>\n",
       "      <td>RT Anies dapat tepuk tangan meriah saat jadi R...</td>\n",
       "      <td>rt anies dapat tepuk tangan meriah saat jadi r...</td>\n",
       "      <td>rt anies dapat tepuk tangan meriah saat jadi r...</td>\n",
       "      <td>rt anies dapat tepuk tangan meriah saat jadi r...</td>\n",
       "      <td>rt anies dapat tepuk tangan riah saat jadi rek...</td>\n",
       "      <td>rt anies tepuk tangan riah rektor wajib mata k...</td>\n",
       "      <td>[rt, anies, tepuk, tangan, riah, rektor, wajib...</td>\n",
       "      <td>rt anies tepuk tangan riah rektor wajib mata k...</td>\n",
       "      <td>[rt, anies, tepuk, tangan, riah, rektor, wajib...</td>\n",
       "      <td>[anies, tepuk, tangan, riah, rektor, wajib, ma...</td>\n",
       "      <td>koruptor antikorupsi mata tangan tepuk putus r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@CIqXqwGAT04tMtx4OCATxjoVq7vv/Y8HeYaIOgMFg8Y= ...</td>\n",
       "      <td>Demografi</td>\n",
       "      <td>[]</td>\n",
       "      <td>emng bener sih, pendukung 01 ada yg goblok, be...</td>\n",
       "      <td>emng bener sih pendukung 01 ada yg goblok begi...</td>\n",
       "      <td>emng bener sih pendukung 01 ada yg goblok begi...</td>\n",
       "      <td>memang benar sih pendukung 01 ada yang goblok ...</td>\n",
       "      <td>memang benar sih dukung 01 ada yang goblok beg...</td>\n",
       "      <td>dukung 01 goblok dukung 02 ridwan kamil skema ...</td>\n",
       "      <td>[dukung, 01, goblok, dukung, 02, ridwan, kamil...</td>\n",
       "      <td>dukung goblok dukung ridwan kamil skema mayori...</td>\n",
       "      <td>[dukung, goblok, dukung, kamil, skema, mayorit...</td>\n",
       "      <td>[dukung, goblok, dukung, kamil, skema, mayorit...</td>\n",
       "      <td>pilih rendah kamil skema mayoritas goblok duku...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @L3R8XFBw3WGbxRPSj0/0hHZTbqVGX7qtfwRg9zmhK7...</td>\n",
       "      <td>Politik</td>\n",
       "      <td>[]</td>\n",
       "      <td>RT Sewaktu anies bersikap kritis ke kinerja pa...</td>\n",
       "      <td>rt sewaktu anies bersikap kritis ke kinerja pa...</td>\n",
       "      <td>rt sewaktu anies bersikap kritis ke kinerja pa...</td>\n",
       "      <td>rt sewaktu anies bersikap kritis ke kinerja pa...</td>\n",
       "      <td>rt waktu anies sikap kritis ke kerja pak prabo...</td>\n",
       "      <td>rt anies sikap kritis kerja prabowo anggap sop...</td>\n",
       "      <td>[rt, anies, sikap, kritis, kerja, prabowo, ang...</td>\n",
       "      <td>rt anies sikap kritis kerja prabowo anggap sop...</td>\n",
       "      <td>[rt, anies, sikap, kritis, kerja, prabowo, ang...</td>\n",
       "      <td>[anies, sikap, kritis, kerja, prabowo, anggap,...</td>\n",
       "      <td>kritis hormat tengil standar anggap prabowo gi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anies Baswedan Harap ASN termasuk TNI dan Polr...</td>\n",
       "      <td>Politik</td>\n",
       "      <td>[]</td>\n",
       "      <td>Anies Baswedan Harap ASN termasuk TNI dan Polr...</td>\n",
       "      <td>anies baswedan harap asn termasuk tni dan polr...</td>\n",
       "      <td>anies baswedan harap asn termasuk tni dan polr...</td>\n",
       "      <td>anies baswedan harap asn termasuk tni dan polr...</td>\n",
       "      <td>anies baswedan harap asn masuk tni dan polri p...</td>\n",
       "      <td>anies baswedan harap asn masuk tni polri pegan...</td>\n",
       "      <td>[anies, baswedan, harap, asn, masuk, tni, polr...</td>\n",
       "      <td>anies baswedan harap asn masuk tni polri pegan...</td>\n",
       "      <td>[anies, harap, masuk, tni, polri, pegang, sump...</td>\n",
       "      <td>[anies, harap, masuk, tni, polri, pegang, sump...</td>\n",
       "      <td>pemilu sumpah tni masuk harap pegang anies polri</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text             label  \\\n",
       "0  Kunjungan Prabowo ini untuk meresmikan dan men...  Sumber Daya Alam   \n",
       "1  RT Anies dapat tepuk tangan meriah saat jadi R...           Politik   \n",
       "2  @CIqXqwGAT04tMtx4OCATxjoVq7vv/Y8HeYaIOgMFg8Y= ...         Demografi   \n",
       "3  RT @L3R8XFBw3WGbxRPSj0/0hHZTbqVGX7qtfwRg9zmhK7...           Politik   \n",
       "4  Anies Baswedan Harap ASN termasuk TNI dan Polr...           Politik   \n",
       "\n",
       "                                 preprocessed_hastag  \\\n",
       "0  [indonesia, sentris, indonesia, hijau, 02melan...   \n",
       "1                        [amin, miskinkan, koruptor]   \n",
       "2                                                 []   \n",
       "3                                                 []   \n",
       "4                                                 []   \n",
       "\n",
       "                                        preprocessed  \\\n",
       "0  Kunjungan Prabowo ini untuk meresmikan dan men...   \n",
       "1  RT Anies dapat tepuk tangan meriah saat jadi R...   \n",
       "2  emng bener sih, pendukung 01 ada yg goblok, be...   \n",
       "3  RT Sewaktu anies bersikap kritis ke kinerja pa...   \n",
       "4  Anies Baswedan Harap ASN termasuk TNI dan Polr...   \n",
       "\n",
       "                                               lower  \\\n",
       "0  kunjungan prabowo ini untuk meresmikan dan men...   \n",
       "1  rt anies dapat tepuk tangan meriah saat jadi r...   \n",
       "2  emng bener sih pendukung 01 ada yg goblok begi...   \n",
       "3  rt sewaktu anies bersikap kritis ke kinerja pa...   \n",
       "4  anies baswedan harap asn termasuk tni dan polr...   \n",
       "\n",
       "                                               clean  \\\n",
       "0  kunjungan prabowo ini untuk meresmikan dan men...   \n",
       "1  rt anies dapat tepuk tangan meriah saat jadi r...   \n",
       "2  emng bener sih pendukung 01 ada yg goblok begi...   \n",
       "3  rt sewaktu anies bersikap kritis ke kinerja pa...   \n",
       "4  anies baswedan harap asn termasuk tni dan polr...   \n",
       "\n",
       "                                              formal  \\\n",
       "0  kunjungan prabowo ini untuk meresmikan dan men...   \n",
       "1  rt anies dapat tepuk tangan meriah saat jadi r...   \n",
       "2  memang benar sih pendukung 01 ada yang goblok ...   \n",
       "3  rt sewaktu anies bersikap kritis ke kinerja pa...   \n",
       "4  anies baswedan harap asn termasuk tni dan polr...   \n",
       "\n",
       "                                          lemmatized  \\\n",
       "0  kunjung prabowo ini untuk resmi dan serah proy...   \n",
       "1  rt anies dapat tepuk tangan riah saat jadi rek...   \n",
       "2  memang benar sih dukung 01 ada yang goblok beg...   \n",
       "3  rt waktu anies sikap kritis ke kerja pak prabo...   \n",
       "4  anies baswedan harap asn masuk tni dan polri p...   \n",
       "\n",
       "                                    stopword_removed  \\\n",
       "0  kunjung prabowo resmi serah proyek bantu air b...   \n",
       "1  rt anies tepuk tangan riah rektor wajib mata k...   \n",
       "2  dukung 01 goblok dukung 02 ridwan kamil skema ...   \n",
       "3  rt anies sikap kritis kerja prabowo anggap sop...   \n",
       "4  anies baswedan harap asn masuk tni polri pegan...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [kunjung, prabowo, resmi, serah, proyek, bantu...   \n",
       "1  [rt, anies, tepuk, tangan, riah, rektor, wajib...   \n",
       "2  [dukung, 01, goblok, dukung, 02, ridwan, kamil...   \n",
       "3  [rt, anies, sikap, kritis, kerja, prabowo, ang...   \n",
       "4  [anies, baswedan, harap, asn, masuk, tni, polr...   \n",
       "\n",
       "                                   stopword_removed2  \\\n",
       "0  kunjung prabowo resmi serah proyek bantu air b...   \n",
       "1  rt anies tepuk tangan riah rektor wajib mata k...   \n",
       "2  dukung goblok dukung ridwan kamil skema mayori...   \n",
       "3  rt anies sikap kritis kerja prabowo anggap sop...   \n",
       "4  anies baswedan harap asn masuk tni polri pegan...   \n",
       "\n",
       "                                                KBBI  \\\n",
       "0  [kunjung, prabowo, resmi, serah, proyek, bantu...   \n",
       "1  [rt, anies, tepuk, tangan, riah, rektor, wajib...   \n",
       "2  [dukung, goblok, dukung, kamil, skema, mayorit...   \n",
       "3  [rt, anies, sikap, kritis, kerja, prabowo, ang...   \n",
       "4  [anies, harap, masuk, tni, polri, pegang, sump...   \n",
       "\n",
       "                                        cleaned_KBBI  \\\n",
       "0  [kunjung, prabowo, resmi, serah, proyek, bantu...   \n",
       "1  [anies, tepuk, tangan, riah, rektor, wajib, ma...   \n",
       "2  [dukung, goblok, dukung, kamil, skema, mayorit...   \n",
       "3  [anies, sikap, kritis, kerja, prabowo, anggap,...   \n",
       "4  [anies, harap, masuk, tni, polri, pegang, sump...   \n",
       "\n",
       "                                         unique_teks  \n",
       "0  titik anak kunjung hijau bantu prabowo emas mu...  \n",
       "1  koruptor antikorupsi mata tangan tepuk putus r...  \n",
       "2  pilih rendah kamil skema mayoritas goblok duku...  \n",
       "3  kritis hormat tengil standar anggap prabowo gi...  \n",
       "4   pemilu sumpah tni masuk harap pegang anies polri  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>hastag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Demografi</th>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ekonomi</th>\n",
       "      <td>367</td>\n",
       "      <td>367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Geografi</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ideologi</th>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pertahanan dan Keamanan</th>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Politik</th>\n",
       "      <td>2972</td>\n",
       "      <td>2972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sosial Budaya</th>\n",
       "      <td>587</td>\n",
       "      <td>587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sumber Daya Alam</th>\n",
       "      <td>192</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         text  hastag\n",
       "label                                \n",
       "Demografi                  62      62\n",
       "Ekonomi                   367     367\n",
       "Geografi                   20      20\n",
       "Ideologi                  400     400\n",
       "Pertahanan dan Keamanan   400     400\n",
       "Politik                  2972    2972\n",
       "Sosial Budaya             587     587\n",
       "Sumber Daya Alam          192     192"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_23600\\2170106849.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_clean['TEKS'] = data_clean['cleaned_KBBI'].apply(lambda x : ' '.join(x))\n"
     ]
    }
   ],
   "source": [
    "data_clean['TEKS'] = data_clean['cleaned_KBBI'].apply(lambda x : ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean.to_csv(\"./dataset/processed_dataset/processed_dataset.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean[['stopword_removed2','label']].dropna().to_csv(\"latih_lagi.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SatriaData24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
